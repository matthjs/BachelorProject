agent_id,agent_type,hyperparams,num_episodes (train),avg return train,stdev return train,max return train,execution time (sec) train,VRAM usage (GB) train,Energy usage (J) train,p_val_cuml_return_train_>,W-statistic_cuml,num_episodes (eval),avg return eval,stdev return eval,max return eval,execution time (sec) eval,VRAM usage (GB) eval,Energy usage (J) eval,p_val_return_eval_>,W-statistic_return_eval
random,random,{},100.0,-176.846,106.477,-2.623,18.127,-0.169,50.27,0.5,0.0,5.0,-150.5,53.183,-107.45,0.036,0.0,0.0,0.5,0.0
DQN (MLP),sb_dqn,"{'policy': 'MlpPolicy', 'learning_rate': 0.00063, 'batch_size': 128, 'buffer_size': 50000, 'learning_starts': 0, 'gamma': 0.99, 'target_update_interval': 250, 'train_freq': 4, 'gradient_steps': -1, 'exploration_fraction': 0.12, 'exploration_final_eps': 0.1, 'policy_kwargs': {'net_arch': [256, 256]}}",100.0,-53.66,102.185,-9999999.0,0.003,0.0,0.0,0.0,10.05,5.0,32.31,157.351,199.244,2.718,0.0,126.388,0.024,1.984
DQN (Linear),sb_dqn,"{'policy': 'MlpPolicy', 'learning_rate': 0.00063, 'batch_size': 128, 'buffer_size': 50000, 'learning_starts': 0, 'gamma': 0.99, 'target_update_interval': 250, 'train_freq': 4, 'gradient_steps': -1, 'exploration_fraction': 0.12, 'exploration_final_eps': 0.1, 'policy_kwargs': {'net_arch': []}}",100.0,-256.592,158.981,-9999999.0,0.002,0.0,0.0,1.0,-10.597,5.0,-186.055,140.702,-34.773,0.355,0.0,20.179,0.623,-0.313
