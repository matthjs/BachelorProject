agent_id,agent_type,hyperparams,num_episodes (train),avg return train,stdev return train,max return train,execution time (sec) train,VRAM usage (GB) train,Energy usage (J) train,p_val_cuml_return_train_>,W-statistic_cuml,num_episodes (eval),avg return eval,stdev return eval,max return eval,execution time (sec) eval,VRAM usage (GB) eval,Energy usage (J) eval,p_val_return_eval_>,W-statistic_return_eval
random,random,{},700.0,-186.846,112.623,29.97,135.891,0.0,201.466,0.5,0.0,30.0,-159.473,110.517,19.207,0.324,0.0,10.658,0.5,0.0
gpq_agent_3,gpq_agent,"{'gp_model_str': 'deep_gp', 'discount_factor': 0.99, 'batch_size': 128, 'replay_buffer_size': 128, 'exploring_starts': 0, 'max_dataset_size': 3584, 'kernel_type': 'matern', 'sparsification_threshold': None, 'strategy': 'thompson_sampling', 'posterior_observation_noise': False, 'num_inducing_points': 100, 'gp_fit_num_epochs': 1, 'gp_fit_batch_size': 512, 'gp_fit_num_batches': 7, 'gp_fit_learning_rate': 0.005, 'gp_fit_random_batching': True, 'dgp_hidden_layers_config': [{'output_dims': 1, 'mean_type': 'linear'}, {'output_dims': 1, 'mean_type': 'linear'}, {'output_dims': 1, 'mean_type': 'linear'}, {'output_dims': None, 'mean_type': 'constant'}]}",1.0,-116.15,99.454,-197.121,21.154,0.531,1052.153,0.0,23.807,30.0,-85.782,97.109,227.474,230.673,0.0,8116.87,0.016,2.144
gpq_agent_3,gpq_agent,{},1.0,-116.15,99.454,-197.121,21.154,0.531,1052.153,0.0,23.807,,,,,,,,,
random,random,{},700.0,-186.846,112.623,29.97,135.891,0.0,201.466,0.5,0.0,,,,,,,,,
gpq_agent_3,gpq_agent,{},,,,,,,,,,,,,,,,,,
random,random,{},,,,,,,,,,,,,,,,,,
sb_dqn_1,sb_dqn,"{'policy': 'MlpPolicy', 'learning_rate': 0.00063, 'batch_size': 128, 'buffer_size': 50000, 'learning_starts': 0, 'gamma': 0.99, 'target_update_interval': 250, 'train_freq': 4, 'gradient_steps': -1, 'exploration_fraction': 0.12, 'exploration_final_eps': 0.1, 'policy_kwargs': {'net_arch': [256, 256]}}",1000.0,58.937,144.002,324.661,1080.121,0.678,5399.596,0.0,37.043,30.0,70.322,135.907,280.746,2.68,0.0,78.583,0.0,5.662
sb_dqn_2,sb_dqn,"{'policy': 'MlpPolicy', 'learning_rate': 0.00063, 'batch_size': 128, 'buffer_size': 50000, 'learning_starts': 0, 'gamma': 0.99, 'target_update_interval': 250, 'train_freq': 4, 'gradient_steps': -1, 'exploration_fraction': 0.12, 'exploration_final_eps': 0.1, 'policy_kwargs': {'net_arch': []}}",1000.0,-320.16,181.788,66.433,310.127,-0.024,1131.775,1.0,-18.556,30.0,-552.264,232.284,-264.828,1.549,0.0,43.071,1.0,-6.416
