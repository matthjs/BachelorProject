agent_id,agent_type,hyperparams,num_episodes (train),avg return train,stdev return train,execution time (sec) train,VRAM usage (GB) train,Energy usage (J) train,p_val_cuml_return_train_>,W-statistic_cuml,num_episodes (eval),avg return eval,stdev return eval,execution time (sec) eval,VRAM usage (GB) eval,Energy usage (J) eval,p_val_return_eval_>,W-statistic_return_eval
random,random,{},200.0,23.105,12.326,6.403,-0.03,8.705,0.5,0.0,10.0,23.4,15.601,0.003,0.0,2.784,0.5,0.0
gpsarsa_agent_1,gpsarsa_agent,"{'gp_model_str': 'exact_gp', 'discount_factor': 0.99, 'batch_size': 32, 'replay_buffer_size': 64, 'exploring_starts': 100, 'max_dataset_size': 2000, 'kernel_type': 'rbf', 'sparsification_threshold': None, 'strategy': 'thompson_sampling'}",200.0,31.54,22.247,173.77,18.368,19006.519,0.0,15.222,10.0,12.9,3.213,2.123,0.0,71.903,0.993,-2.457
sb_dqn_1,sb_dqn,"{'policy': 'MlpPolicy', 'learning_rate': 0.0023, 'batch_size': 64, 'buffer_size': 100000, 'learning_starts': 1000, 'gamma': 0.99, 'target_update_interval': 10, 'train_freq': 256, 'gradient_steps': 128, 'exploration_fraction': 0.16, 'exploration_final_eps': 0.04, 'policy_kwargs': {'net_arch': [256, 256]}}",200.0,39.705,35.319,6.904,-0.01,353.736,0.0,4.305,10.0,181.3,84.685,0.437,0.0,29.752,0.001,3.099
sb_dqn_2,sb_dqn,"{'policy': 'MlpPolicy', 'learning_rate': 0.0023, 'batch_size': 64, 'buffer_size': 100000, 'learning_starts': 1000, 'gamma': 0.99, 'target_update_interval': 10, 'train_freq': 256, 'gradient_steps': 128, 'exploration_fraction': 0.16, 'exploration_final_eps': 0.04, 'policy_kwargs': {'net_arch': []}}",200.0,17.875,9.084,1.718,-0.024,56.891,1.0,-16.207,10.0,16.1,6.839,0.023,0.0,0.0,0.925,-1.436
