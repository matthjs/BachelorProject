agent_id,agent_type,hyperparams,num_episodes (train),avg return train,stdev return train,execution time (sec) train,VRAM usage (GB) train,Energy usage (J) train,p_val_cuml_return_train_>,W-statistic_cuml,num_episodes (eval),avg return eval,stdev return eval,execution time (sec) eval,VRAM usage (GB) eval,Energy usage (J) eval,p_val_return_eval_>,W-statistic_return_eval
random,random,{},300.0,-178.595,107.378,49.192,-0.073,34.727,0.5,0.0,10.0,-175.305,71.274,0.026,0.0,0.0,0.5,0.0
gpq_agent_2,gpq_agent,"{'gp_model_str': 'variational_gp', 'discount_factor': 0.99, 'batch_size': 32, 'replay_buffer_size': 64, 'exploring_starts': 100, 'max_dataset_size': 2000, 'kernel_type': 'rbf', 'sparsification_threshold': None, 'strategy': 'upper_confidence_bound'}",300.0,-379.28,192.643,294.828,1.804,12619.545,1.0,-20.986,10.0,-468.004,82.385,5.966,0.0,186.182,1.0,-3.78
sb_dqn_1,sb_dqn,"{'policy': 'MlpPolicy', 'learning_rate': 0.00063, 'batch_size': 128, 'buffer_size': 50000, 'learning_starts': 0, 'gamma': 0.99, 'target_update_interval': 250, 'train_freq': 4, 'gradient_steps': -1, 'exploration_fraction': 0.12, 'exploration_final_eps': 0.1, 'policy_kwargs': {'net_arch': [256, 256]}}",300.0,-35.819,146.688,131.099,0.041,722.942,0.0,12.628,10.0,171.552,158.798,1.486,0.0,48.24,0.001,3.175
sb_dqn_2,sb_dqn,"{'policy': 'MlpPolicy', 'learning_rate': 0.00063, 'batch_size': 128, 'buffer_size': 50000, 'learning_starts': 0, 'gamma': 0.99, 'target_update_interval': 250, 'train_freq': 4, 'gradient_steps': -1, 'exploration_fraction': 0.12, 'exploration_final_eps': 0.1, 'policy_kwargs': {'net_arch': []}}",300.0,-284.297,156.375,87.244,0.011,379.384,1.0,-17.558,10.0,-205.055,137.044,0.29,0.0,9.35,0.619,-0.302
