model:
  n_envs: 8
  policy: 'MlpPolicy'
  n_steps: 32
  batch_size: 256
  gae_lambda: 0.8
  gamma: 0.98
  n_epochs: 20
  ent_coef: 0.0
  learning_rate: 0.001
  clip_range: 0.2

training:
  n_timesteps: !!float 1e5