{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Online GP update demo"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "589b92343f29ce2b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The goal of this notebook is to look into how to properly update an (exact inference) Gaussian process (GP) regression model where the initial training data is None and the GP is continuously conditioned on incoming training data in an online fashion."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4c19672f042e4d"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-28T15:26:29.946787Z",
     "start_time": "2024-04-28T15:26:28.745639700Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.kernels import RBFKernel\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "# Define a custom ExactGP model\n",
    "class GPRegressionModel(ExactGP):\n",
    "    def __init__(self, likelihood):\n",
    "        super(GPRegressionModel, self).__init__(None, None, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Initialize likelihood\n",
    "likelihood = GaussianLikelihood()\n",
    "\n",
    "# Initialize model\n",
    "model = GPRegressionModel(likelihood)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T15:26:30.222346500Z",
     "start_time": "2024-04-28T15:26:29.949789500Z"
    }
   },
   "id": "4669da101ab46f96"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "GaussianLikelihood(\n  (noise_covar): HomoskedasticNoise(\n    (raw_noise_constraint): GreaterThan(1.000E-04)\n  )\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set model and likelihood to training mode\n",
    "model.train()\n",
    "likelihood.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T15:26:30.231814500Z",
     "start_time": "2024-04-28T15:26:30.227873800Z"
    }
   },
   "id": "b61321d4ca3db25"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T15:26:30.533190100Z",
     "start_time": "2024-04-28T15:26:30.234322300Z"
    }
   },
   "id": "4092398c74bd4974"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "# Define a function for the training loop\n",
    "def train_model(train_x_, train_y_, model_, mll, likelihood, optimizer, iter=10):\n",
    "    # Find optimal model hyperparameters\n",
    "    model_.train()\n",
    "    likelihood.train()\n",
    "    \n",
    "    for itr in range(iter):\n",
    "        # Zero gradients from previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = model_(train_x_)\n",
    "        # Calculate loss\n",
    "        loss = -mll(output, train_y_)    # might need to do .mean() for batched inputs\n",
    "        \n",
    "        # print('Loss shape:', loss.shape)  # Add this line for diagnostic\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "            itr + 1, iter, loss.item(),\n",
    "            model_.covar_module.base_kernel.lengthscale.item(),\n",
    "            model_.likelihood.noise.item()\n",
    "        ))\n",
    "    \n",
    "        optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T15:26:30.545194700Z",
     "start_time": "2024-04-28T15:26:30.538188600Z"
    }
   },
   "id": "4a419ab113018d97"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def plot(model, likelihood, train_x, train_y, test_x):\n",
    "    # Get into evaluation (predictive posterior) mode\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    \n",
    "    # Test points are regularly spaced along [0,1]\n",
    "    # Make predictions by feeding model through likelihood\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        observed_pred = likelihood(model(test_x))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Initialize plot\n",
    "        f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "    \n",
    "        # Get upper and lower confidence bounds\n",
    "        lower, upper = observed_pred.confidence_region()\n",
    "        # Plot training data as black stars\n",
    "        ax.plot(train_x.squeeze().numpy(), train_y.numpy(), 'k*')\n",
    "        # Plot predictive means as blue line\n",
    "        ax.plot(test_x.squeeze().numpy(), observed_pred.mean.numpy(), 'b')\n",
    "        # Shade between the lower and upper confidence bounds\n",
    "        ax.fill_between(test_x.squeeze().numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\n",
    "        ax.set_ylim([-3, 3])\n",
    "        ax.legend(['Observed Data', 'Mean', 'Confidence'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T15:26:30.864866100Z",
     "start_time": "2024-04-28T15:26:30.545194700Z"
    }
   },
   "id": "e0ab09f979bed9ce"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6])\n",
      "Iter 1/10 - Loss: 1.411   lengthscale: 0.693   noise: 0.693\n",
      "Iter 2/10 - Loss: 1.400   lengthscale: 0.644   noise: 0.744\n",
      "Iter 3/10 - Loss: 1.393   lengthscale: 0.598   noise: 0.772\n",
      "Iter 4/10 - Loss: 1.384   lengthscale: 0.554   noise: 0.766\n",
      "Iter 5/10 - Loss: 1.373   lengthscale: 0.513   noise: 0.744\n",
      "Iter 6/10 - Loss: 1.362   lengthscale: 0.473   noise: 0.715\n",
      "Iter 7/10 - Loss: 1.350   lengthscale: 0.436   noise: 0.683\n",
      "Iter 8/10 - Loss: 1.338   lengthscale: 0.402   noise: 0.650\n",
      "Iter 9/10 - Loss: 1.325   lengthscale: 0.369   noise: 0.620\n",
      "Iter 10/10 - Loss: 1.311   lengthscale: 0.338   noise: 0.591\n",
      "torch.Size([12])\n",
      "Iter 1/10 - Loss: 1.139   lengthscale: 0.310   noise: 0.565\n",
      "Iter 2/10 - Loss: 1.118   lengthscale: 0.283   noise: 0.538\n",
      "Iter 3/10 - Loss: 1.093   lengthscale: 0.258   noise: 0.508\n",
      "Iter 4/10 - Loss: 1.068   lengthscale: 0.235   noise: 0.476\n",
      "Iter 5/10 - Loss: 1.044   lengthscale: 0.213   noise: 0.444\n",
      "Iter 6/10 - Loss: 1.024   lengthscale: 0.194   noise: 0.411\n",
      "Iter 7/10 - Loss: 1.005   lengthscale: 0.177   noise: 0.379\n",
      "Iter 8/10 - Loss: 0.987   lengthscale: 0.163   noise: 0.348\n",
      "Iter 9/10 - Loss: 0.968   lengthscale: 0.152   noise: 0.319\n",
      "Iter 10/10 - Loss: 0.950   lengthscale: 0.144   noise: 0.291\n",
      "torch.Size([18])\n",
      "Iter 1/10 - Loss: 0.775   lengthscale: 0.138   noise: 0.265\n",
      "Iter 2/10 - Loss: 0.752   lengthscale: 0.134   noise: 0.240\n",
      "Iter 3/10 - Loss: 0.730   lengthscale: 0.131   noise: 0.217\n",
      "Iter 4/10 - Loss: 0.707   lengthscale: 0.130   noise: 0.196\n",
      "Iter 5/10 - Loss: 0.685   lengthscale: 0.130   noise: 0.176\n",
      "Iter 6/10 - Loss: 0.663   lengthscale: 0.131   noise: 0.159\n",
      "Iter 7/10 - Loss: 0.642   lengthscale: 0.133   noise: 0.142\n",
      "Iter 8/10 - Loss: 0.622   lengthscale: 0.136   noise: 0.128\n",
      "Iter 9/10 - Loss: 0.605   lengthscale: 0.140   noise: 0.115\n",
      "Iter 10/10 - Loss: 0.590   lengthscale: 0.145   noise: 0.103\n",
      "torch.Size([23])\n",
      "Iter 1/10 - Loss: 0.499   lengthscale: 0.151   noise: 0.093\n",
      "Iter 2/10 - Loss: 0.485   lengthscale: 0.158   noise: 0.084\n",
      "Iter 3/10 - Loss: 0.473   lengthscale: 0.167   noise: 0.076\n",
      "Iter 4/10 - Loss: 0.465   lengthscale: 0.176   noise: 0.070\n",
      "Iter 5/10 - Loss: 0.461   lengthscale: 0.186   noise: 0.064\n",
      "Iter 6/10 - Loss: 0.461   lengthscale: 0.197   noise: 0.059\n",
      "Iter 7/10 - Loss: 0.465   lengthscale: 0.206   noise: 0.055\n",
      "Iter 8/10 - Loss: 0.471   lengthscale: 0.215   noise: 0.052\n",
      "Iter 9/10 - Loss: 0.478   lengthscale: 0.220   noise: 0.049\n",
      "Iter 10/10 - Loss: 0.482   lengthscale: 0.223   noise: 0.047\n",
      "torch.Size([29])\n",
      "Iter 1/10 - Loss: 0.663   lengthscale: 0.222   noise: 0.046\n",
      "Iter 2/10 - Loss: 0.658   lengthscale: 0.220   noise: 0.047\n",
      "Iter 3/10 - Loss: 0.644   lengthscale: 0.217   noise: 0.049\n",
      "Iter 4/10 - Loss: 0.626   lengthscale: 0.214   noise: 0.051\n",
      "Iter 5/10 - Loss: 0.607   lengthscale: 0.210   noise: 0.055\n",
      "Iter 6/10 - Loss: 0.588   lengthscale: 0.207   noise: 0.059\n",
      "Iter 7/10 - Loss: 0.572   lengthscale: 0.205   noise: 0.063\n",
      "Iter 8/10 - Loss: 0.560   lengthscale: 0.203   noise: 0.069\n",
      "Iter 9/10 - Loss: 0.550   lengthscale: 0.202   noise: 0.074\n",
      "Iter 10/10 - Loss: 0.544   lengthscale: 0.202   noise: 0.080\n",
      "torch.Size([36])\n",
      "Iter 1/10 - Loss: 0.539   lengthscale: 0.202   noise: 0.087\n",
      "Iter 2/10 - Loss: 0.534   lengthscale: 0.204   noise: 0.093\n",
      "Iter 3/10 - Loss: 0.531   lengthscale: 0.208   noise: 0.099\n",
      "Iter 4/10 - Loss: 0.529   lengthscale: 0.212   noise: 0.106\n",
      "Iter 5/10 - Loss: 0.530   lengthscale: 0.217   noise: 0.112\n",
      "Iter 6/10 - Loss: 0.531   lengthscale: 0.223   noise: 0.117\n",
      "Iter 7/10 - Loss: 0.533   lengthscale: 0.228   noise: 0.122\n",
      "Iter 8/10 - Loss: 0.536   lengthscale: 0.234   noise: 0.126\n",
      "Iter 9/10 - Loss: 0.538   lengthscale: 0.238   noise: 0.129\n",
      "Iter 10/10 - Loss: 0.540   lengthscale: 0.241   noise: 0.131\n",
      "torch.Size([41])\n",
      "Iter 1/10 - Loss: 0.505   lengthscale: 0.243   noise: 0.132\n",
      "Iter 2/10 - Loss: 0.506   lengthscale: 0.243   noise: 0.133\n",
      "Iter 3/10 - Loss: 0.505   lengthscale: 0.243   noise: 0.132\n",
      "Iter 4/10 - Loss: 0.504   lengthscale: 0.241   noise: 0.131\n",
      "Iter 5/10 - Loss: 0.502   lengthscale: 0.238   noise: 0.129\n",
      "Iter 6/10 - Loss: 0.500   lengthscale: 0.235   noise: 0.126\n",
      "Iter 7/10 - Loss: 0.497   lengthscale: 0.232   noise: 0.123\n",
      "Iter 8/10 - Loss: 0.495   lengthscale: 0.228   noise: 0.120\n",
      "Iter 9/10 - Loss: 0.493   lengthscale: 0.225   noise: 0.117\n",
      "Iter 10/10 - Loss: 0.491   lengthscale: 0.222   noise: 0.113\n",
      "torch.Size([46])\n",
      "Iter 1/10 - Loss: 0.454   lengthscale: 0.220   noise: 0.110\n",
      "Iter 2/10 - Loss: 0.452   lengthscale: 0.218   noise: 0.106\n",
      "Iter 3/10 - Loss: 0.450   lengthscale: 0.217   noise: 0.103\n",
      "Iter 4/10 - Loss: 0.449   lengthscale: 0.216   noise: 0.100\n",
      "Iter 5/10 - Loss: 0.449   lengthscale: 0.216   noise: 0.097\n",
      "Iter 6/10 - Loss: 0.449   lengthscale: 0.216   noise: 0.094\n",
      "Iter 7/10 - Loss: 0.449   lengthscale: 0.217   noise: 0.092\n",
      "Iter 8/10 - Loss: 0.449   lengthscale: 0.218   noise: 0.090\n",
      "Iter 9/10 - Loss: 0.449   lengthscale: 0.219   noise: 0.088\n",
      "Iter 10/10 - Loss: 0.450   lengthscale: 0.220   noise: 0.087\n",
      "torch.Size([56])\n",
      "Iter 1/10 - Loss: 0.393   lengthscale: 0.221   noise: 0.086\n",
      "Iter 2/10 - Loss: 0.393   lengthscale: 0.222   noise: 0.085\n",
      "Iter 3/10 - Loss: 0.393   lengthscale: 0.223   noise: 0.085\n",
      "Iter 4/10 - Loss: 0.393   lengthscale: 0.225   noise: 0.084\n",
      "Iter 5/10 - Loss: 0.393   lengthscale: 0.226   noise: 0.084\n",
      "Iter 6/10 - Loss: 0.393   lengthscale: 0.228   noise: 0.084\n",
      "Iter 7/10 - Loss: 0.393   lengthscale: 0.229   noise: 0.084\n",
      "Iter 8/10 - Loss: 0.393   lengthscale: 0.230   noise: 0.084\n",
      "Iter 9/10 - Loss: 0.393   lengthscale: 0.230   noise: 0.085\n",
      "Iter 10/10 - Loss: 0.393   lengthscale: 0.230   noise: 0.085\n",
      "torch.Size([64])\n",
      "Iter 1/10 - Loss: 0.404   lengthscale: 0.230   noise: 0.086\n",
      "Iter 2/10 - Loss: 0.403   lengthscale: 0.229   noise: 0.087\n",
      "Iter 3/10 - Loss: 0.403   lengthscale: 0.229   noise: 0.088\n",
      "Iter 4/10 - Loss: 0.403   lengthscale: 0.229   noise: 0.089\n",
      "Iter 5/10 - Loss: 0.402   lengthscale: 0.229   noise: 0.090\n",
      "Iter 6/10 - Loss: 0.402   lengthscale: 0.229   noise: 0.091\n",
      "Iter 7/10 - Loss: 0.402   lengthscale: 0.229   noise: 0.092\n",
      "Iter 8/10 - Loss: 0.402   lengthscale: 0.229   noise: 0.093\n",
      "Iter 9/10 - Loss: 0.402   lengthscale: 0.229   noise: 0.095\n",
      "Iter 10/10 - Loss: 0.402   lengthscale: 0.229   noise: 0.096\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Initialize empty training data\n",
    "train_x = torch.empty(0)\n",
    "train_y = torch.empty(0)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "# Now, suppose you start receiving new data\n",
    "for i in range(10):  # Assuming you receive 5 batches of new data\n",
    "    # Generate new data (for demonstration purposes)\n",
    "    new_data_x = torch.linspace(0, 1, 5 + random.randint(0, 5))\n",
    "    new_data_y = torch.sin(new_data_x * (2 * 3.1416)) + torch.randn(new_data_x.size()) * 0.3\n",
    "\n",
    "    plot(model, likelihood, train_x, train_y, new_data_x)\n",
    "\n",
    "    # Update model with new data\n",
    "    if train_x is not None:\n",
    "        train_x = torch.cat([train_x, new_data_x])\n",
    "        train_y = torch.cat([train_y, new_data_y])\n",
    "        \n",
    "    print(train_y.shape)\n",
    "        \n",
    "    # Update model with new data\n",
    "    # This is not an efficient update.\n",
    "    model.set_train_data(train_x, train_y.squeeze(), strict=False)\n",
    "\n",
    "    train_model(train_x, train_y, model, mll, likelihood, optimizer, 10)\n",
    "        \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T15:26:32.199846200Z",
     "start_time": "2024-04-28T15:26:30.870872100Z"
    }
   },
   "id": "342d6fe843d5855a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The aforementioned is not efficient. Conditioning each time takes $O((N+N_*)^3)$ time, where $N_*$ is the number of new samples and $N$ is the existing train samples.\n",
    "\n",
    "What we want is a more efficient approach that updates the that takes advantage of linear algebraic identities. Instead of doing essentially:\n",
    "```\n",
    "updated_model = deepcopy(model)\n",
    "updated_model.set_train_data(torch.cat((train_x, new_x)), torch.cat((train_y, new_y)), strict=False)\n",
    "```\n",
    "We can do:\n",
    "```\n",
    "updated_model = model.get_fantasy_model(new_x, new_y)\n",
    "```\n",
    "which is in $O((N_*)^2N)$ time."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c89167976446c49c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
