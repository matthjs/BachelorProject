{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-20T13:54:35.991567600Z",
     "start_time": "2024-05-20T13:54:35.803794400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y-mean -> 1.0274299453993332\n",
      "Pre-transform X:\n",
      "tensor([[1.5768, 1.1933],\n",
      "        [1.5130, 1.9399],\n",
      "        [0.9817, 0.9119],\n",
      "        [1.2342, 1.8790],\n",
      "        [1.4635, 1.6702],\n",
      "        [1.1987, 1.0060],\n",
      "        [1.9782, 1.3785],\n",
      "        [1.7853, 1.4926],\n",
      "        [0.6445, 1.3008],\n",
      "        [1.8866, 1.7320]], dtype=torch.float64)\n",
      "Mean -> 1.4383391601648818\n",
      "Transformed X:\n",
      "tensor([[0.6990, 0.2737],\n",
      "        [0.6512, 1.0000],\n",
      "        [0.2529, 0.0000],\n",
      "        [0.4421, 0.9408],\n",
      "        [0.6141, 0.7377],\n",
      "        [0.4156, 0.0916],\n",
      "        [1.0000, 0.4540],\n",
      "        [0.8554, 0.5649],\n",
      "        [0.0000, 0.3783],\n",
      "        [0.9313, 0.7978]], dtype=torch.float64)\n",
      "Mean -> 0.5550238259229798\n",
      "Transformed Test X:\n",
      "tensor([[-0.3890, -0.5239],\n",
      "        [-0.2514, -0.0018],\n",
      "        [ 0.0415, -0.2632],\n",
      "        [-0.1312, -0.2806],\n",
      "        [ 0.0025, -0.7293]])\n",
      "Predicted mean:\n",
      "tensor([[1.1217],\n",
      "        [1.0461],\n",
      "        [1.3790],\n",
      "        [1.2606],\n",
      "        [1.2414]], dtype=torch.float64)\n",
      "Confidence region:\n",
      "tensor([0.5321, 0.7151, 1.1113, 0.8937, 0.6483], dtype=torch.float64), tensor([1.7113, 1.3771, 1.6466, 1.6275, 1.8345], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from botorch.models.transforms.input import InputStandardize\n",
    "from botorch import fit_gpytorch_mll\n",
    "import torch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms import Normalize, Standardize, ChainedInputTransform\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "# Generate some example training data\n",
    "train_X = torch.rand(10, 2, dtype=torch.double) + torch.rand(10, 2, dtype=torch.double) + torch.rand(10, 2, dtype=torch.double)  # 20 samples, 2 features\n",
    "train_Y = torch.sin(train_X[:, 0]) + torch.cos(train_X[:, 1])  # Some function of the inputs\n",
    "print(f\"Y-mean -> {train_Y.mean()}\")\n",
    "\n",
    "# Define the input transformations\n",
    "normalize = Normalize(d=train_X.shape[-1])\n",
    "standardize = InputStandardize(d=train_X.shape[-1])\n",
    "input_transform = normalize# ChainedInputTransform(tf1=standardize, tf2=normalize)\n",
    "output_transform = Standardize(m=1)\n",
    "\n",
    "print(f\"Pre-transform X:\\n{train_X}\")\n",
    "print(f\"Mean -> {train_X.mean()}\")\n",
    "# Apply the transformations to the training data\n",
    "transformed_X = input_transform(train_X)\n",
    "print(f\"Transformed X:\\n{transformed_X}\")\n",
    "print(f\"Mean -> {transformed_X.mean()}\")\n",
    "\n",
    "# Define and train the GP model\n",
    "gp = SingleTaskGP(train_X, train_Y.unsqueeze(-1), input_transform=input_transform,\n",
    "                  outcome_transform=output_transform)\n",
    "mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "\n",
    "# Fit the model\n",
    "fit_gpytorch_mll(mll)\n",
    "\n",
    "# Test the transformations during prediction\n",
    "test_X = torch.rand(5, 2)  # 5 test samples\n",
    "transformed_test_X = input_transform(test_X)\n",
    "print(f\"Transformed Test X:\\n{transformed_test_X}\")\n",
    "\n",
    "# Make predictions\n",
    "gp.eval()\n",
    "with torch.no_grad():\n",
    "    posterior = gp.posterior(test_X)\n",
    "    mean = posterior.mean\n",
    "    lower, upper = posterior.mvn.confidence_region()\n",
    "    print(f\"Predicted mean:\\n{mean}\")\n",
    "    print(f\"Confidence region:\\n{lower}, {upper}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y-mean -> 1.2979449091156885\n",
      "Pre-transform X:\n",
      "tensor([[0.8560, 1.4173],\n",
      "        [1.9688, 0.8463],\n",
      "        [1.7538, 1.3478],\n",
      "        [1.3922, 0.5609],\n",
      "        [1.8664, 1.7617],\n",
      "        [1.3709, 0.6106],\n",
      "        [1.4558, 1.3360],\n",
      "        [1.5754, 1.0900],\n",
      "        [1.0111, 1.1575],\n",
      "        [0.9741, 1.4501]], dtype=torch.float64)\n",
      "Mean -> 1.2901350348098481\n",
      "Transformed X:\n",
      "tensor([[0.0000, 0.7132],\n",
      "        [1.0000, 0.2376],\n",
      "        [0.8068, 0.6553],\n",
      "        [0.4819, 0.0000],\n",
      "        [0.9080, 1.0000],\n",
      "        [0.4627, 0.0414],\n",
      "        [0.5390, 0.6455],\n",
      "        [0.6465, 0.4406],\n",
      "        [0.1394, 0.4968],\n",
      "        [0.1062, 0.7404]], dtype=torch.float64)\n",
      "Mean -> 0.503065986366696\n",
      "Transformed Test X:\n",
      "tensor([[-0.7547,  0.0783],\n",
      "        [-0.4770, -0.3840],\n",
      "        [-0.6239,  0.3345],\n",
      "        [ 0.0415,  0.3118],\n",
      "        [-0.7068, -0.4434]], dtype=torch.float64)\n",
      "Predicted mean:\n",
      "tensor([[1.7604],\n",
      "        [1.9487],\n",
      "        [1.5126],\n",
      "        [1.5379],\n",
      "        [1.9506]], dtype=torch.float64)\n",
      "Confidence region:\n",
      "tensor([1.5598, 1.4765, 1.3148, 1.3397, 1.4212], dtype=torch.float64), tensor([1.9609, 2.4208, 1.7104, 1.7362, 2.4800], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from botorch import fit_gpytorch_mll\n",
    "from botorch.models import MixedSingleTaskGP\n",
    "from botorch.models.transforms import Normalize, Standardize, ChainedInputTransform\n",
    "from botorch.models.transforms.input import InputStandardize\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "# Generate some example training data\n",
    "train_X = torch.rand(10, 2, dtype=torch.double) + torch.rand(10, 2, dtype=torch.double) + torch.rand(10, 2, dtype=torch.double)  # 10 samples, 2 features\n",
    "train_Y = torch.sin(train_X[:, 0]) + torch.cos(train_X[:, 1])  # Some function of the inputs\n",
    "print(f\"Y-mean -> {train_Y.mean()}\")\n",
    "\n",
    "# Define the input transformations\n",
    "normalize = Normalize(d=train_X.shape[-1])\n",
    "standardize = InputStandardize(d=train_X.shape[-1])\n",
    "input_transform = ChainedInputTransform(tf1=standardize, tf2=normalize)\n",
    "output_transform = Standardize(m=1)\n",
    "\n",
    "print(f\"Pre-transform X:\\n{train_X}\")\n",
    "print(f\"Mean -> {train_X.mean()}\")\n",
    "# Apply the transformations to the training data\n",
    "transformed_X = input_transform(train_X)\n",
    "print(f\"Transformed X:\\n{transformed_X}\")\n",
    "print(f\"Mean -> {transformed_X.mean()}\")\n",
    "\n",
    "# Define and train the GP model\n",
    "# Assuming the first dimension is categorical and the second is continuous\n",
    "cat_dims = [0]  # indices of the categorical dimensions\n",
    "gp = MixedSingleTaskGP(train_X, train_Y.unsqueeze(-1), cat_dims=cat_dims, \n",
    "                       input_transform=input_transform, outcome_transform=output_transform)\n",
    "mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "\n",
    "# Fit the model\n",
    "fit_gpytorch_mll(mll)\n",
    "\n",
    "# Test the transformations during prediction\n",
    "test_X = torch.rand(5, 2, dtype=torch.double)  # 5 test samples\n",
    "transformed_test_X = input_transform(test_X)\n",
    "print(f\"Transformed Test X:\\n{transformed_test_X}\")\n",
    "\n",
    "# Make predictions\n",
    "gp.eval()\n",
    "with torch.no_grad():\n",
    "    posterior = gp.posterior(test_X)\n",
    "    mean = posterior.mean\n",
    "    lower, upper = posterior.mvn.confidence_region()\n",
    "    print(f\"Predicted mean:\\n{mean}\")\n",
    "    print(f\"Confidence region:\\n{lower}, {upper}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T13:57:20.452436200Z",
     "start_time": "2024-05-20T13:57:19.326516500Z"
    }
   },
   "id": "b465b207d08e4697"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Test X:\n",
      "tensor([[-0.2403,  0.2990],\n",
      "        [-0.0699, -0.2115],\n",
      "        [-0.0565, -0.1867],\n",
      "        [-0.4090, -0.4091],\n",
      "        [-0.1857, -0.1123]], dtype=torch.float64)\n",
      "Predicted mean:\n",
      "tensor([[1.5520],\n",
      "        [1.9172],\n",
      "        [1.9092],\n",
      "        [1.9500],\n",
      "        [1.8792]], dtype=torch.float64)\n",
      "Confidence region:\n",
      "tensor([1.3536, 1.5968, 1.6072, 1.4537, 1.6243], dtype=torch.float64), tensor([1.7505, 2.2377, 2.2113, 2.4463, 2.1341], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Define and train the GP model\n",
    "# Assuming the first dimension is categorical and the second is continuous\n",
    "cat_dims = [0]  # indices of the categorical dimensions\n",
    "gp = MixedSingleTaskGP(train_X, train_Y.unsqueeze(-1), cat_dims=cat_dims, \n",
    "                       input_transform=input_transform, outcome_transform=output_transform)\n",
    "mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "\n",
    "# Fit the model\n",
    "fit_gpytorch_mll(mll)\n",
    "\n",
    "# Test the transformations during prediction\n",
    "test_X = torch.rand(5, 2, dtype=torch.double)  # 5 test samples\n",
    "transformed_test_X = input_transform(test_X)\n",
    "print(f\"Transformed Test X:\\n{transformed_test_X}\")\n",
    "\n",
    "# Make predictions\n",
    "gp.eval()\n",
    "with torch.no_grad():\n",
    "    posterior = gp.posterior(test_X)\n",
    "    mean = posterior.mean\n",
    "    lower, upper = posterior.mvn.confidence_region()\n",
    "    print(f\"Predicted mean:\\n{mean}\")\n",
    "    print(f\"Confidence region:\\n{lower}, {upper}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T13:57:49.650428100Z",
     "start_time": "2024-05-20T13:57:48.978930700Z"
    }
   },
   "id": "7a80c0e9d3a7be0d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Attempt to replicate scenario"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a67bc0aea5a7a7bf"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y-mean -> 1.3763063820719779\n",
      "Pre-transform X:\n",
      "tensor([[1.0000, 0.8475, 0.4174],\n",
      "        [0.0000, 0.5489, 0.6960],\n",
      "        [2.0000, 0.7019, 0.6020],\n",
      "        [0.0000, 0.9936, 0.4755],\n",
      "        [2.0000, 0.1989, 0.1537],\n",
      "        [1.0000, 0.5213, 0.8255],\n",
      "        [2.0000, 0.7160, 0.0482],\n",
      "        [1.0000, 0.0907, 0.4729],\n",
      "        [0.0000, 0.3687, 0.4942],\n",
      "        [0.0000, 0.4802, 0.4210]], dtype=torch.float64)\n",
      "Mean -> 0.6357978286383106\n",
      "Transformed X:\n",
      "tensor([[0.5000, 0.8382, 0.4750],\n",
      "        [0.0000, 0.5074, 0.8335],\n",
      "        [1.0000, 0.6769, 0.7125],\n",
      "        [0.0000, 1.0000, 0.5498],\n",
      "        [1.0000, 0.1198, 0.1356],\n",
      "        [0.5000, 0.4769, 1.0000],\n",
      "        [1.0000, 0.6926, 0.0000],\n",
      "        [0.5000, 0.0000, 0.5464],\n",
      "        [0.0000, 0.3079, 0.5738],\n",
      "        [0.0000, 0.4314, 0.4796]], dtype=torch.float64)\n",
      "Mean -> 0.49524299745423667\n",
      "Transformed Test X:\n",
      "tensor([[1.0000, 0.0482, 0.7040],\n",
      "        [1.0000, 0.4506, 0.2670],\n",
      "        [1.0000, 0.2146, 0.0394],\n",
      "        [1.0000, 0.5226, 0.1680],\n",
      "        [0.0000, 0.5100, 0.5480]], dtype=torch.float64)\n",
      "Predicted mean:\n",
      "tensor([[0.9655],\n",
      "        [1.4440],\n",
      "        [1.2800],\n",
      "        [1.5168],\n",
      "        [1.4140]], dtype=torch.float64)\n",
      "Confidence region:\n",
      "tensor([0.9579, 1.4391, 1.2735, 1.5106, 1.4122], dtype=torch.float64), tensor([0.9731, 1.4489, 1.2865, 1.5231, 1.4157], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from botorch import fit_gpytorch_mll\n",
    "from botorch.models import MixedSingleTaskGP\n",
    "from botorch.models.transforms import Normalize, Standardize, ChainedInputTransform\n",
    "from botorch.models.transforms.input import InputStandardize\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "# Generate some example training data\n",
    "# 10 samples, 3 features (2 continuous and 1 discrete)\n",
    "continuous_features = torch.rand(10, 2, dtype=torch.double)\n",
    "discrete_feature = torch.randint(0, 3, (10, 1), dtype=torch.double)  # Discrete feature with 3 categories\n",
    "train_X = torch.cat([discrete_feature, continuous_features], dim=1)\n",
    "train_Y = torch.sin(train_X[:, 1]) + torch.cos(train_X[:, 2])  # Some function of the continuous inputs\n",
    "print(f\"Y-mean -> {train_Y.mean()}\")\n",
    "\n",
    "# Define the input transformations\n",
    "input_transform = Normalize(d=train_X.shape[-1])\n",
    "output_transform = Standardize(m=1)\n",
    "\n",
    "print(f\"Pre-transform X:\\n{train_X}\")\n",
    "print(f\"Mean -> {train_X.mean()}\")\n",
    "\n",
    "# Apply the transformations to the training data\n",
    "transformed_X = input_transform(train_X)\n",
    "print(f\"Transformed X:\\n{transformed_X}\")\n",
    "print(f\"Mean -> {transformed_X.mean()}\")\n",
    "\n",
    "# Define and train the GP model\n",
    "# Assuming the first dimension is categorical and the next two are continuous\n",
    "cat_dims = [0]  # indices of the categorical dimensions\n",
    "gp = MixedSingleTaskGP(train_X, train_Y.unsqueeze(-1), cat_dims=cat_dims, \n",
    "                       input_transform=input_transform, outcome_transform=output_transform)\n",
    "mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "\n",
    "# Fit the model\n",
    "fit_gpytorch_mll(mll)\n",
    "\n",
    "# Test the transformations during prediction\n",
    "# Generate test data with 5 samples\n",
    "continuous_features_test = torch.rand(5, 2, dtype=torch.double)\n",
    "discrete_feature_test = torch.randint(0, 3, (5, 1), dtype=torch.double)  # Discrete feature with 3 categories\n",
    "test_X = torch.cat([discrete_feature_test, continuous_features_test], dim=1)\n",
    "transformed_test_X = input_transform(test_X)\n",
    "print(f\"Transformed Test X:\\n{transformed_test_X}\")\n",
    "\n",
    "# Make predictions\n",
    "gp.eval()\n",
    "with torch.no_grad():\n",
    "    posterior = gp.posterior(test_X)\n",
    "    mean = posterior.mean\n",
    "    lower, upper = posterior.mvn.confidence_region()\n",
    "    print(f\"Predicted mean:\\n{mean}\")\n",
    "    print(f\"Confidence region:\\n{lower}, {upper}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T14:17:16.362762200Z",
     "start_time": "2024-05-20T14:17:15.915888900Z"
    }
   },
   "id": "4b833f3b29017e36"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
