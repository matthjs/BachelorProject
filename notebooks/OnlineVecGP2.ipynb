{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Online GP regression with thomson sampling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c7a31028334d102"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from contextlib import ExitStack\n",
    "\n",
    "import gpytorch\n",
    "import gpytorch.settings as gpts\n",
    "import torch\n",
    "from gpytorch.constraints import Interval\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.kernels import MaternKernel, RFFKernel, ScaleKernel\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from torch.quasirandom import SobolEngine\n",
    "\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.generation import MaxPosteriorSampling\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.test_functions import Hartmann\n",
    "from botorch.utils.transforms import unnormalize\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.double\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T12:02:03.340866Z",
     "start_time": "2024-05-07T12:02:03.337322Z"
    }
   },
   "id": "3683df9055f0b6cd",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "hart6 = Hartmann(dim=3, negate=True).to(device=device, dtype=dtype)\n",
    "dim = hart6.dim\n",
    "\n",
    "\n",
    "def eval_objective(x):\n",
    "    \"\"\"This is a helper function we use to unnormalize and evalaute a point\"\"\"\n",
    "    return hart6(unnormalize(x, hart6.bounds))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T12:02:03.368568Z",
     "start_time": "2024-05-07T12:02:03.361296Z"
    }
   },
   "id": "5bc467b37c3cadb9",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_initial_points(dim, n_pts, seed=None):\n",
    "    sobol = SobolEngine(dimension=dim, scramble=True, seed=seed)\n",
    "    X_init = sobol.draw(n=n_pts).to(dtype=dtype, device=device)\n",
    "    return X_init"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T12:02:03.372666Z",
     "start_time": "2024-05-07T12:02:03.369560Z"
    }
   },
   "id": "37be413c3a1a44d9",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_batch(\n",
    "    X,\n",
    "    Y,\n",
    "    batch_size,\n",
    "    n_candidates,\n",
    "    sampler=\"cholesky\",  # \"cholesky\", \"ciq\", \"rff\"\n",
    "    use_keops=False,\n",
    "):\n",
    "    assert sampler in (\"cholesky\", \"ciq\", \"rff\", \"lanczos\")\n",
    "    assert X.min() >= 0.0 and X.max() <= 1.0 and torch.all(torch.isfinite(Y))\n",
    "\n",
    "    # NOTE: We probably want to pass in the default priors in SingleTaskGP here later\n",
    "    kernel_kwargs = {\"nu\": 2.5, \"ard_num_dims\": X.shape[-1]}\n",
    "    if sampler == \"rff\":\n",
    "        base_kernel = RFFKernel(**kernel_kwargs, num_samples=1024)\n",
    "    else:\n",
    "        base_kernel = (\n",
    "            MaternKernel(**kernel_kwargs)\n",
    "            if use_keops\n",
    "            else MaternKernel(**kernel_kwargs)\n",
    "        )\n",
    "    covar_module = ScaleKernel(base_kernel)\n",
    "\n",
    "    # Fit a GP model\n",
    "    train_Y = (Y - Y.mean()) / Y.std()\n",
    "    likelihood = GaussianLikelihood(noise_constraint=Interval(1e-8, 1e-3))\n",
    "    model = SingleTaskGP(X, train_Y, likelihood=likelihood, covar_module=covar_module)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "\n",
    "    # Draw samples on a Sobol sequence\n",
    "    sobol = SobolEngine(X.shape[-1], scramble=True)\n",
    "    X_cand = sobol.draw(n_candidates).to(dtype=dtype, device=device)\n",
    "\n",
    "    # Thompson sample\n",
    "    with ExitStack() as es:\n",
    "        if sampler == \"cholesky\":\n",
    "            es.enter_context(gpts.max_cholesky_size(float(\"inf\")))\n",
    "        elif sampler == \"ciq\":\n",
    "            es.enter_context(gpts.fast_computations(covar_root_decomposition=True))\n",
    "            es.enter_context(gpts.max_cholesky_size(0))\n",
    "            es.enter_context(gpts.ciq_samples(True))\n",
    "            es.enter_context(\n",
    "                gpts.minres_tolerance(2e-3)\n",
    "            )  # Controls accuracy and runtime\n",
    "            es.enter_context(gpts.num_contour_quadrature(15))\n",
    "        elif sampler == \"lanczos\":\n",
    "            es.enter_context(\n",
    "                gpts.fast_computations(\n",
    "                    covar_root_decomposition=True, log_prob=True, solves=True\n",
    "                )\n",
    "            )\n",
    "            es.enter_context(gpts.max_lanczos_quadrature_iterations(10))\n",
    "            es.enter_context(gpts.max_cholesky_size(0))\n",
    "            es.enter_context(gpts.ciq_samples(False))\n",
    "        elif sampler == \"rff\":\n",
    "            es.enter_context(gpts.fast_computations(covar_root_decomposition=True))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        thompson_sampling = MaxPosteriorSampling(model=model, replacement=False)\n",
    "        X_next = thompson_sampling(X_cand, num_samples=batch_size)\n",
    "\n",
    "    return X_next"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T12:02:03.382191Z",
     "start_time": "2024-05-07T12:02:03.373454Z"
    }
   },
   "id": "2c30073accd87619",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def run_optimization(\n",
    "    sampler, n_candidates, n_init, max_evals, batch_size, use_keops=False, seed=None\n",
    "):\n",
    "    X = get_initial_points(dim, n_init, seed)\n",
    "    \n",
    "    print(X.shape)\n",
    "    \n",
    "    \n",
    "    Y = torch.tensor(\n",
    "        [eval_objective(x) for x in X], dtype=dtype, device=device\n",
    "    ).unsqueeze(-1)\n",
    "    print(f\"{len(X)}) Best value: {Y.max().item():.2e}\")\n",
    "\n",
    "    while len(X) < max_evals:\n",
    "        # Create a batch\n",
    "        start = time.monotonic()\n",
    "        X_next = generate_batch(\n",
    "            X=X,\n",
    "            Y=Y,\n",
    "            batch_size=min(batch_size, max_evals - len(X)),\n",
    "            n_candidates=n_candidates,\n",
    "            sampler=sampler,\n",
    "            use_keops=use_keops,\n",
    "        )\n",
    "        end = time.monotonic()\n",
    "        print(f\"Generated batch in {end - start:.1f} seconds\")\n",
    "        Y_next = torch.tensor(\n",
    "            [eval_objective(x) for x in X_next], dtype=dtype, device=device\n",
    "        ).unsqueeze(-1)\n",
    "\n",
    "        # Append data\n",
    "        X = torch.cat((X, X_next), dim=0)\n",
    "        Y = torch.cat((Y, Y_next), dim=0)\n",
    "\n",
    "        print(f\"{len(X)}) Best value: {Y.max().item():.2e}\")\n",
    "    return X, Y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T12:02:03.393498Z",
     "start_time": "2024-05-07T12:02:03.383448Z"
    }
   },
   "id": "6e1bd1603749eed2",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "n_init = 10\n",
    "max_evals = 50\n",
    "seed = 12345  # To get the same Sobol points\n",
    "\n",
    "shared_args = {\n",
    "    \"n_init\": n_init,\n",
    "    \"max_evals\": max_evals,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"seed\": seed,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T12:02:03.403949Z",
     "start_time": "2024-05-07T12:02:03.394246Z"
    }
   },
   "id": "dc8421fb847e0a92",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# This tutorial will run much faster if KeOps + a GPU is used\n",
    "USE_KEOPS = False\n",
    "\n",
    "if USE_KEOPS:\n",
    "    import pykeops\n",
    "    from gpytorch.kernels.keops import MaternKernel as KMaternKernel\n",
    "\n",
    "N_CAND = 10_000\n",
    "if USE_KEOPS:\n",
    "    N_CAND = 50_000\n",
    "if SMOKE_TEST:\n",
    "    N_CAND = 10\n",
    "    \n",
    "N_CAND_CHOL = 10_000 if not SMOKE_TEST else 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T12:02:03.412741Z",
     "start_time": "2024-05-07T12:02:03.404745Z"
    }
   },
   "id": "ab3046da0380a195",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T12:02:03.421484Z",
     "start_time": "2024-05-07T12:02:03.413535Z"
    }
   },
   "id": "677f88cac2478ac0",
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cholesky"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f9a4a3b2f9981e7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exact GP inference, is in $O(N^3)$ where $N$ is the size of the dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9957593886bd2bca"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3])\n",
      "10) Best value: 2.89e+00\n",
      "Generated batch in 0.8 seconds\n",
      "15) Best value: 2.89e+00\n",
      "Generated batch in 0.6 seconds\n",
      "20) Best value: 3.78e+00\n",
      "Generated batch in 0.6 seconds\n",
      "25) Best value: 3.85e+00\n",
      "Generated batch in 0.6 seconds\n",
      "30) Best value: 3.85e+00\n",
      "Generated batch in 0.5 seconds\n",
      "35) Best value: 3.85e+00\n",
      "Generated batch in 0.5 seconds\n",
      "40) Best value: 3.86e+00\n",
      "Generated batch in 0.5 seconds\n",
      "45) Best value: 3.86e+00\n",
      "Generated batch in 0.6 seconds\n",
      "50) Best value: 3.86e+00\n",
      "peak memory: 4898.50 MiB, increment: 0.03 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit X_chol, Y_chol = run_optimization(\"cholesky\", N_CAND_CHOL, **shared_args)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T12:02:08.293800Z",
     "start_time": "2024-05-07T12:02:03.422332Z"
    }
   },
   "id": "7e98f3aece48b6a8",
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Fourier Features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f7862cf9383131b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Approximate exact inference. Is in $O(KN)$ where $K$ is the number of Fourier features and $N$ is the size of the dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f829edab3a86955"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3])\n",
      "10) Best value: 2.89e+00\n",
      "Generated batch in 0.2 seconds\n",
      "15) Best value: 3.11e+00\n",
      "Generated batch in 0.3 seconds\n",
      "20) Best value: 3.84e+00\n",
      "Generated batch in 0.3 seconds\n",
      "25) Best value: 3.85e+00\n",
      "Generated batch in 0.2 seconds\n",
      "30) Best value: 3.86e+00\n",
      "Generated batch in 0.2 seconds\n",
      "35) Best value: 3.86e+00\n",
      "Generated batch in 0.2 seconds\n",
      "40) Best value: 3.86e+00\n",
      "Generated batch in 0.2 seconds\n",
      "45) Best value: 3.86e+00\n",
      "Generated batch in 0.2 seconds\n",
      "50) Best value: 3.86e+00\n",
      "peak memory: 4898.51 MiB, increment: 0.01 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit X_rff, Y_rff = run_optimization(\"rff\", N_CAND, **shared_args)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T12:02:10.344493Z",
     "start_time": "2024-05-07T12:02:08.294864Z"
    }
   },
   "id": "aab029201f21c183",
   "execution_count": 48
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
