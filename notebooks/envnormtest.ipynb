{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Environment - Raw Observation: (array([ 1.0166168e-03,  1.4094908e+00,  1.0295093e-01, -6.3525908e-02,\n",
      "       -1.1711508e-03, -2.3319928e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32), {})\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 14\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m5\u001B[39m):\n\u001B[1;32m     13\u001B[0m     action \u001B[38;5;241m=\u001B[39m env_single\u001B[38;5;241m.\u001B[39maction_space\u001B[38;5;241m.\u001B[39msample()  \u001B[38;5;66;03m# Sample a random action\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m     obs_single, reward, done, info \u001B[38;5;241m=\u001B[39m env_single\u001B[38;5;241m.\u001B[39mstep(action)\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSingle Environment - Raw Observation:\u001B[39m\u001B[38;5;124m\"\u001B[39m, obs_single)\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# Close the single environment\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# Create the LunarLander-v2 environment directly\n",
    "env_single = gym.make('LunarLander-v2')\n",
    "\n",
    "# Reset the environment and print the first observation\n",
    "obs_single = env_single.reset()\n",
    "print(\"Single Environment - Raw Observation:\", obs_single)\n",
    "\n",
    "# Take a few steps in the environment and print observations\n",
    "for _ in range(5):\n",
    "    action = env_single.action_space.sample()  # Sample a random action\n",
    "    obs_single, reward, done, info = env_single.step(action)\n",
    "    print(\"Single Environment - Raw Observation:\", obs_single)\n",
    "\n",
    "# Close the single environment\n",
    "env_single.close()\n",
    "\n",
    "# Create a DummyVecEnv with the LunarLander-v2 environment\n",
    "env_vec = DummyVecEnv([lambda: gym.make('LunarLander-v2')])\n",
    "\n",
    "# Reset the vectorized environment and print the first observation\n",
    "obs_vec = env_vec.reset()\n",
    "print(\"Vectorized Environment - Raw Observation:\", obs_vec[0])  # Since DummyVecEnv is used, access the first observation\n",
    "\n",
    "# Take a few steps in the vectorized environment and print observations\n",
    "for _ in range(5):\n",
    "    action = env_vec.action_space.sample()  # Sample a random action\n",
    "    obs_vec, reward, done = env_vec.step([action])\n",
    "    print(\"Vectorized Environment - Raw Observation:\", obs_vec[0])  # Since DummyVecEnv is used, access the first observation\n",
    "\n",
    "# Close the vectorized environment\n",
    "env_vec.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-20T13:19:17.420561Z",
     "start_time": "2024-06-20T13:19:16.185795Z"
    }
   },
   "id": "ef2d439ab7b62661",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-20T12:44:29.310135Z",
     "start_time": "2024-06-20T12:44:29.298551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.4916738e-05  8.1541361e-03 -4.8611863e-03 -9.6039148e-04\n",
      "   6.3702137e-05  1.2501442e-03  0.0000000e+00  0.0000000e+00]]\n",
      "Box([-1.5       -1.5       -5.        -5.        -3.1415927 -5.\n",
      " -0.        -0.       ], [1.5       1.5       5.        5.        3.1415927 5.        1.\n",
      " 1.       ], (8,), float32)\n",
      "Discrete(4)\n",
      "Standard Environment Observations:\n",
      "(8,)\n",
      "[ 0.00449829  1.4247646   0.22032492  0.294843   -0.00285054 -0.00391279\n",
      "  0.          0.        ]\n",
      "(8,)\n",
      "[ 6.6262246e-03  1.4308078e+00  2.1111552e-01  2.6858357e-01\n",
      " -1.1987421e-03  3.3039160e-02  0.0000000e+00  0.0000000e+00]\n",
      "(8,)\n",
      "[8.7540625e-03 1.4362508e+00 2.1111016e-01 2.4191222e-01 4.5242021e-04\n",
      " 3.3026829e-02 0.0000000e+00 0.0000000e+00]\n",
      "(8,)\n",
      "[0.01081858 1.4411051  0.20317777 0.21574761 0.00369337 0.06482522\n",
      " 0.         0.        ]\n",
      "(8,)\n",
      "[0.01276817 1.4466997  0.19221547 0.24863718 0.00639979 0.05413328\n",
      " 0.         0.        ]\n",
      "(8,)\n",
      "[0.01454659 1.4527061  0.17590733 0.26694757 0.00831106 0.03822911\n",
      " 0.         0.        ]\n",
      "(8,)\n",
      "[0.01625338 1.4581034  0.16693467 0.23985477 0.01202157 0.07421691\n",
      " 0.         0.        ]\n",
      "(8,)\n",
      "[0.01796007 1.4629011  0.16692318 0.21318975 0.01573039 0.07418308\n",
      " 0.         0.        ]\n",
      "(8,)\n",
      "[0.01961021 1.4679636  0.16149975 0.2249599  0.01921448 0.06968795\n",
      " 0.         0.        ]\n",
      "(8,)\n",
      "[0.02116928 1.4724228  0.1500731  0.19810475 0.02498765 0.11547377\n",
      " 0.         0.        ]\n",
      "\n",
      "Normalized Environment Observations:\n",
      "(1, 8)\n",
      "[[-0.83284223 -0.60276824 -0.74420553 -0.81862944  0.9873266   1.1329006\n",
      "   0.          0.        ]]\n",
      "(1, 8)\n",
      "[[-1.2037591  -0.96690226 -0.66588193 -0.8136674   1.3625441   1.2812747\n",
      "   0.          0.        ]]\n",
      "(1, 8)\n",
      "[[-1.3751336  -1.223644   -0.57110685 -0.8554445   1.4840904   0.9937803\n",
      "   0.          0.        ]]\n",
      "(1, 8)\n",
      "[[-1.4648278  -1.3895885  -0.58684057 -0.9173187   1.5780412   1.298136\n",
      "   0.          0.        ]]\n",
      "(1, 8)\n",
      "[[-1.5132697  -1.4700063  -0.46494263 -0.692276    1.6255581   1.2029854\n",
      "   0.          0.        ]]\n",
      "(1, 8)\n",
      "[[-1.5521778  -1.4991757  -0.64075613 -0.36459017  1.632146    0.84613246\n",
      "   0.          0.        ]]\n",
      "(1, 8)\n",
      "[[-1.5796757  -1.5402905  -0.6788673  -0.59395045  1.6673206   1.2229843\n",
      "   0.          0.        ]]\n",
      "(1, 8)\n",
      "[[-1.5985256 -1.5837071 -0.6301962 -0.7997785  1.6838192  1.081156\n",
      "   0.         0.       ]]\n",
      "(1, 8)\n",
      "[[-1.6166335  -1.5931308  -0.7672669  -0.41212827  1.6882651   0.9170056\n",
      "   0.          0.        ]]\n",
      "(1, 8)\n",
      "[[-1.6315322 -1.6157901 -0.8302573 -0.6735767  1.7184851  1.3730531\n",
      "   0.         0.       ]]\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "\n",
    "# Create the standard Gymnasium environment\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "\n",
    "# Create the normalized environment\n",
    "vec_env = DummyVecEnv([lambda: gym.make(\"LunarLander-v2\")])\n",
    "vec_normalized_env = VecNormalize(vec_env, norm_obs=True, norm_reward=False)\n",
    "\n",
    "print(vec_normalized_env.reset())\n",
    "print(vec_normalized_env.observation_space)\n",
    "print(vec_normalized_env.action_space)\n",
    "\n",
    "# Reset both environments to get initial observations\n",
    "obs_standard, info_standard = env.reset(seed=42)\n",
    "obs_normalized = vec_normalized_env.reset()\n",
    "\n",
    "# Collect observations\n",
    "standard_observations = []\n",
    "normalized_observations = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    # Take an action in both environments\n",
    "    action = env.action_space.sample()  # Use the same action for both environments\n",
    "\n",
    "    # Step in the standard environment\n",
    "    obs_standard, reward, terminated, truncated, info = env.step(action)\n",
    "    standard_observations.append(obs_standard)\n",
    "\n",
    "    # Step in the normalized environment\n",
    "    obs_normalized, reward, terminated, done = vec_normalized_env.step([action])\n",
    "    normalized_observations.append(obs_normalized)\n",
    "\n",
    "    # Reset environments if terminated or truncated\n",
    "    if terminated or truncated:\n",
    "        obs_standard, info_standard = env.reset()\n",
    "        obs_normalized = vec_normalized_env.reset()\n",
    "\n",
    "    # Stop after 10 steps for demonstration\n",
    "    if len(standard_observations) >= 10:\n",
    "        break\n",
    "\n",
    "# Print observations for comparison\n",
    "print(\"Standard Environment Observations:\")\n",
    "for obs in standard_observations:\n",
    "    print(obs.shape)\n",
    "    print(obs)\n",
    "\n",
    "print(\"\\nNormalized Environment Observations:\")\n",
    "for obs in normalized_observations:\n",
    "    print(obs.shape)\n",
    "    print(obs)\n",
    "\n",
    "# Close environments\n",
    "env.close()\n",
    "vec_normalized_env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
